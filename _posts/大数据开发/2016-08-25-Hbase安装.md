---
layout: post  
title: "Hbase安装"
date: 2016-08-25
author: hunterhug
categories: [数据开发]
desc: "Hbase安装"
tags: ["大数据","zookeeper",hbase"]
permalink: "/bigdata/hbase-install.html"
---

# 一.快速安装
> 在单机安装Hbase的方法。会引导你通过shell创建一个表，插入一行，然后删除它，最后停止Hbase。只要10分钟就可以完成以下的操作。

1.下载解压最新版本

选择一个 Apache 下载镜像：http://www.apache.org/dyn/closer.cgi/hbase/，下载 HBase Releases. 点击 stable目录，然后下载后缀为 .tar.gz 的文件; 例如 hbase-0.90.4.tar.gz.

后面需要安装集群，整合到hadoop，所以注意选择与hadoop对应的版本：

选择 Hadoop 版本对HBase部署很关键。下表显示不同HBase支持的Hadoop版本信息。基于HBase版本，应该选择合适的Hadoop版本。我们没有绑定 Hadoop 发行版选择。可以从Apache使用 Hadoop 发行版，或了解一下Hadoop发行商产品： http://wiki.apache.org/hadoop/Distributions%20and%20Commercial%20Support

    Table 2.1. Hadoop version support matrix
        HBase-0.92.x 	HBase-0.94.x 	HBase-0.96
    Hadoop-0.20.205 	S 	X 	X
    Hadoop-0.22.x 	S 	X 	X
    Hadoop-1.0.x 	S 	S 	S
    Hadoop-1.1.x 	NT 	S 	S
    Hadoop-0.23.x 	X 	S 	NT
    Hadoop-2.x 	X 	S 	S

>S = supported and tested,支持

>X = not supported,不支持

>NT = not tested enough.可以运行但测试不充分

由于 HBase 依赖 Hadoop，它配套发布了一个Hadoop jar 文件在它的 lib 下。该套装jar仅用于独立模式。在分布式模式下，Hadoop版本必须和HBase下的版本一致。用你运行的分布式Hadoop版本jar文件替换HBase lib目录下的Hadoop jar文件，以避免版本不匹配问题。确认替换了集群中所有HBase下的jar文件。Hadoop版本不匹配问题有不同表现，但看起来都像挂掉了。

安装：

    $ tar xfz hbase-0.90.4.tar.gz
    $ cd hbase-0.90.4

现在你已经可以启动Hbase了。但是你可能需要先编辑 conf/hbase-site.xml 去配置hbase.rootdir，来选择Hbase将数据写到哪个目录 .

单机配置，只需要如下配置hbase-site.xml：

    <?xml version="1.0"?>  
    <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>  
    <configuration>  
      <property>  
        <name>hbase.rootdir</name>  
        <value>file:///DIRECTORY/hbase</value>  
      </property>  
    </configuration>  

将 DIRECTORY 替换成你期望写文件的目录. 默认 hbase.rootdir 是指向 /tmp/hbase-${user.name} ，也就说你会在重启后丢失数据(重启的时候操作系统会清理/tmp目录)

2.启动 HBase

现在启动Hbase:

    $ ./bin/start-hbase.sh
    
    starting Master, logging to logs/hbase-user-master-example.org.out

现在你运行的是单机模式的Hbaes。所以的服务都运行在一个JVM上，包括Hbase和Zookeeper。Hbase的日志放在logs目录,当你启动出问题的时候，可以检查这个日志。

3.Hbase Shell 练习

用shell连接你的Hbase

    $ ./bin/hbase shell
    
    HBase Shell; enter 'help<RETURN>' for list of supported commands.
    
    Type "exit<RETURN>" to leave the HBase Shell
    
    Version: 0.90.0, r1001068, Fri Sep 24 13:55:42 PDT 2010
    
     
    
    hbase(main):001:0> 

输入 help 然后 <RETURN> 可以看到一列shell命令。这里的帮助很详细，要注意的是表名，行和列需要加引号。

创建一个名为 test 的表，这个表只有一个column family 为 cf。可以列出所有的表来检查创建情况，然后插入些值。

    hbase(main):003:0> create 'test', 'cf'
    
    0 row(s) in 1.2200 seconds
    
    hbase(main):003:0> list 'table'
    
    test
    
    1 row(s) in 0.0550 seconds
    
    hbase(main):004:0> put 'test', 'row1', 'cf:a', 'value1'
    
    0 row(s) in 0.0560 seconds
    
    hbase(main):005:0> put 'test', 'row2', 'cf:b', 'value2'
    
    0 row(s) in 0.0370 seconds
    
    hbase(main):006:0> put 'test', 'row3', 'cf:c', 'value3'
    
    0 row(s) in 0.0450 seconds

以上我们分别插入了3行。第一个行key为row1, 列为 cf:a， 值是 value1。Hbase中的列是由 column family前缀和列的名字组成的，以冒号间隔。例如这一行的列名就是a.

检查插入情况.

Scan这个表，操作如下

    hbase(main):007:0> scan 'test'
    
    ROW        COLUMN+CELL
    
    row1       column=cf:a, timestamp=1288380727188, value=value1
    
    row2       column=cf:b, timestamp=1288380738440, value=value2
    
    row3       column=cf:c, timestamp=1288380747365, value=value3
    
    3 row(s) in 0.0590 seconds

Get一行，操作如下

hbase(main):008:0> get 'test', 'row1'

    COLUMN      CELL
    
    cf:a        timestamp=1288380727188, value=value1
    
    1 row(s) in 0.0400 seconds

disable 再 drop 这张表，可以清除你刚刚的操作

    hbase(main):012:0> disable 'test'
    
    0 row(s) in 1.0930 seconds
    
    hbase(main):013:0> drop 'test'
    
    0 row(s) in 0.0770 seconds 

关闭shell

    hbase(main):014:0> exit

4.停止 HBase

运行停止脚本来停止HBase.

    $ ./bin/stop-hbase.sh
    
    stopping hbase...............

# 二.集群安装注意

1）  Java：（hadoop已经安装了）

2）  Hadoop 0.20.x / Hadoop-2.x 已经正确安装，并且可以启动 HDFS 系统, 可参考的Hadoop安装文档：Hadoop集群配置（最全面总结）http://blog.csdn.net/hguisu/article/details/7237395

3）  ssh 必须安装ssh，sshd 也必须运行，这样Hadoop的脚本才可以远程操控其他的Hadoop和Hbase进程。ssh之间必须都打通，不用密码都可以登录，详细方法可以Google一下 ("ssh passwordless login").

4）  NTP：集群的时钟要保证基本的一致。稍有不一致是可以容忍的，但是很大的不一致会 造成奇怪的行为。 运行 NTP 或者其他什么东西来同步你的时间.

如果你查询的时候或者是遇到奇怪的故障，可以检查一下系统时间是否正确!

     设置集群各个节点时钟：date -s “2012-02-13 14:00:00”

5）  ulimit 和 nproc:

Base是数据库，会在同一时间使用很多的文件句柄。大多数linux系统使用的默认值1024是不能满足的，会导致FAQ: Why do I see "java.io.IOException...(Too manyopen files)" in my logs?异常。还可能会发生这样的异常

     2010-04-06 03:04:37,542 INFO org.apache.hadoop.hdfs.DFSClient: ExceptionincreateBlockOutputStream java.io.EOFException

     2010-04-06 03:04:37,542 INFO org.apache.hadoop.hdfs.DFSClient:Abandoning block blk_-6935524980745310745_1391901

所以你需要修改你的最大文件句柄限制。可以设置到10k. 你还需要修改 hbase 用户的 nproc，如果过低会造成 OutOfMemoryError异常。

需要澄清的，这两个设置是针对操作系统的，不是Hbase本身的。有一个常见的错误是Hbase运行的用户，和设置最大值的用户不是一个用户。在Hbase启动的时候，第一行日志会现在ulimit信息，所以你最好检查一下。 


可以先查看当前用户 ulimit：

    ulimit -n

设置ulimit:

如果你使用的是Ubuntu,你可以这样设置:在文件 /etc/security/limits.conf 添加一行，如:

    hadoop  -       nofile 32768

可以把 hadoop 替换成你运行Hbase和Hadoop的用户。如果你用两个用户，你就需要配两个。还有配nproc hard 和 softlimits. 如:

    hadoop soft/hard nproc 32000

在 /etc/pam.d/common-session 加上这一行:

    session required pam_limits.so

否则在 /etc/security/limits.conf上的配置不会生效.

还有注销再登录，这些配置才能生效!

7）修改Hadoop HDFS Datanode同时处理文件的上限：dfs.datanode.max.xcievers

一个 Hadoop HDFS Datanode 有一个同时处理文件的上限. 这个参数叫 xcievers (Hadoop的作者把这个单词拼错了). 在你加载之前，先确认下你有没有配置这个文件conf/hdfs-site.xml里面的xceivers参数，至少要有4096:

      <property>

       <name>dfs.datanode.max.xcievers</name>

        <value>4096</value>

      </property>

对于HDFS修改配置要记得重启.

如果没有这一项配置，你可能会遇到奇怪的失败。你会在Datanode的日志中看到xcievers exceeded，但是运行起来会报 missing blocks错误。例如: 02/12/1220:10:31 INFO hdfs.DFSClient: Could not obtain blockblk_XXXXXXXXXXXXXXXXXXXXXX_YYYYYYYY from any node: java.io.IOException: No livenodes contain current block. Will get new block locations from namenode andretry...

8）继承hadoop安装的说明：

每个机子/etc/hosts

    10.64.56.74  node2 （master）
    
    10.64.56.76  node1  （slave）
    
    10.64.56.77  node3 （slave）

9） 继续使用hadoop用户安装

    Chown –R hadoop /usr/local/hbase

# 分布式模式配置
1.配置conf/hbase-env.sh

        # exportJAVA_HOME=/usr/java/jdk1.6.0/
        exportJAVA_HOME=/usr/lib/jvm/java-6-sun-1.6.0.26
        # Tell HBase whether it should manage it'sown instance of Zookeeper or not.
        export HBASE_MANAGES_ZK=true

不管是什么模式，你都需要编辑 conf/hbase-env.sh来告知Hbase java的安装路径.在这个文件里你还可以设置Hbase的运行环境，诸如 heapsize和其他 JVM有关的选项, 还有Log文件地址，等等. 设置 JAVA_HOME指向 java安装的路径.

一个分布式运行的Hbase依赖一个zookeeper集群。所有的节点和客户端都必须能够访问zookeeper。默认的情况下Hbase会管理一个zookeep集群。这个集群会随着Hbase的启动而启动。当然，你也可以自己管理一个zookeeper集群，但需要配置Hbase。你需要修改conf/hbase-env.sh里面的HBASE_MANAGES_ZK 来切换。这个值默认是true的，作用是让Hbase启动的时候同时也启动zookeeper.

让Hbase使用一个现有的不被Hbase托管的Zookeep集群，需要设置 conf/hbase-env.sh文件中的HBASE_MANAGES_ZK 属性为 false

        # Tell HBase whether it should manage it's own instanceof Zookeeper or not.
        exportHBASE_MANAGES_ZK=false

2.配置conf/hbase-site.xml
    <configuration>  
      
        <property>  
      
        <name>hbase.rootdir</name>  
      
        <value>hdfs://node1:49002/hbase</value>  
      
        <description>The directory shared byRegionServers.  
      
        </description>  
      
      </property>  
      
      <property>  
      
        <name>hbase.cluster.distributed</name>  
      
        <value>true</value>  
      
        <description>The mode the clusterwill be in. Possible values are  
      
          false: standalone and pseudo-distributedsetups with managed Zookeeper  
      
          true: fully-distributed with unmanagedZookeeper Quorum (see hbase-env.sh)  
      
        </description>  
      
      </property>  
      
       
      
        <property>  
      
          <name>hbase.zookeeper.property.clientPort</name>  
      
          <value>2222</value>  
      
          <description>Property fromZooKeeper's config zoo.cfg.  
      
          The port at which the clients willconnect.  
      
          </description>  
      
        </property>  
      
        <property>  
      
          <name>hbase.zookeeper.quorum</name>  
      
          <value>node1,node2,node3</value>  
      
          <description>Comma separated listof servers in the ZooKeeper Quorum.  
      
          For example,"host1.mydomain.com,host2.mydomain.com,host3.mydomain.com".  
      
          By default this is set to localhost forlocal and pseudo-distributed modes  
      
          of operation. For a fully-distributedsetup, this should be set to a full  
      
          list of ZooKeeper quorum servers. IfHBASE_MANAGES_ZK is set in hbase-env.sh  
      
          this is the list of servers which we willstart/stop ZooKeeper on.  
      
          </description>  
      
        </property>  
      
        <property>  
      
          <name>hbase.zookeeper.property.dataDir</name>  
      
          <value>/home/hadoop/zookeeper</value>  
      
          <description>Property fromZooKeeper's config zoo.cfg.  
      
          The directory where the snapshot isstored.  
      
          </description>  
      
        </property>  
      
      </configuration>  



要想运行完全分布式模式，加一个属性 hbase.cluster.distributed 设置为 true 然后把 hbase.rootdir 设置为HDFS的NameNode的位置。 例如，你的namenode运行在node1，端口是49002 你期望的目录是 /hbase,使用如下的配置：hdfs://node1:49002/hbase

>hbase.rootdir：这个目录是region server的共享目录，用来持久化Hbase。URL需要是'完全正确'的，还要包含文件系统的scheme。
例如，要表示hdfs中的'/hbase'目录，namenode 运行在node1的49002端口。则需要设置为hdfs://node1:49002/hbase。默认情况下Hbase是写到/tmp的。
不改这个配置，数据会在重启的时候丢失。默认: file:///tmp/hbase-${user.name}/hbase

>hbase.cluster.distributed ：Hbase的运行模式。false是单机模式，true是分布式模式。若为false,Hbase和Zookeeper会运行在同一个JVM里面。默认: false

在hbase-site.xml配置zookeeper：

当Hbase管理zookeeper的时候，你可以通过修改zoo.cfg来配置zookeeper，

一个更加简单的方法是在 conf/hbase-site.xml里面修改zookeeper的配置。Zookeeer的配置是作为property写在 hbase-site.xml里面的。

对于zookeepr的配置，你至少要在 hbase-site.xml中列出zookeepr的ensemble servers，具体的字段是 hbase.zookeeper.quorum. 该这个字段的默认值是 localhost，这个值对于分布式应用显然是不可以的. (远程连接无法使用)。

>hbase.zookeeper.property.clientPort：ZooKeeper的zoo.conf中的配置。 客户端连接的端口。

>hbase.zookeeper.quorum：Zookeeper集群的地址列表，用逗号分割。例如："host1.mydomain.com,host2.mydomain.com,host3.mydomain.com".默认是localhost,是给伪分布式用的。要修改才能在完全分布式的情况下使用。如果在hbase-env.sh设置了HBASE_MANAGES_ZK，这些ZooKeeper节点就会和Hbase一起启动。
默认: localhost
运行一个zookeeper也是可以的，但是在生产环境中，你最好部署3，5，7个节点。部署的越多，可靠性就越高，当然只能部署奇数个，偶数个是不可以的。你需要给每个zookeeper 1G左右的内存，如果可能的话，最好有独立的磁盘。 (独立磁盘可以确保zookeeper是高性能的。).如果你的集群负载很重，不要把Zookeeper和RegionServer运行在同一台机器上面。就像DataNodes 和 TaskTrackers一样

>hbase.zookeeper.property.dataDir：ZooKeeper的zoo.conf中的配置。 快照的存储位置
把ZooKeeper保存数据的目录地址改掉。默认值是 /tmp ，这里在重启的时候会被操作系统删掉，可以把它修改到 /home/hadoop/zookeeper (这个路径hadoop用户拥有操作权限)
对于独立的Zookeeper，要指明Zookeeper的host和端口。可以在 hbase-site.xml中设置, 也可以在Hbase的CLASSPATH下面加一个zoo.cfg配置文件。 HBase 会优先加载 zoo.cfg 里面的配置，把hbase-site.xml里面的覆盖掉.
参见 http://www.yankay.com/wp-content/hbase/book.html#hbase_default_configurations可以查找hbase.zookeeper.property 前缀，找到关于zookeeper的配置。

3.配置conf/regionservers

Node1

Node2

完全分布式模式的还需要修改conf/regionservers. 在这里列出了你希望运行的全部 HRegionServer，一行写一个host (就像Hadoop里面的 slaves 一样). 列在这里的server会随着集群的启动而启动，集群的停止而停止.

 
4.替换hadoop的jar包

hbase基本的配置完了。

查看hbase的lib目录下。

    ls lib |grep hadoop
    
    hadoop-annotations-2.1.0-beta.jar
    hadoop-auth-2.1.0-beta.jar
    hadoop-client-2.1.0-beta.jar
    hadoop-common-2.1.0-beta.jar
    hadoop-hdfs-2.1.0-beta.jar
    hadoop-hdfs-2.1.0-beta-tests.jar
    hadoop-mapreduce-client-app-2.1.0-beta.jar
    hadoop-mapreduce-client-common-2.1.0-beta.jar
    hadoop-mapreduce-client-core-2.1.0-beta.jar
    hadoop-mapreduce-client-jobclient-2.1.0-beta.jar
    hadoop-mapreduce-client-jobclient-2.1.0-beta-tests.jar
    hadoop-mapreduce-client-shuffle-2.1.0-beta.jar
    hadoop-yarn-api-2.1.0-beta.jar
    hadoop-yarn-client-2.1.0-beta.jar
    hadoop-yarn-common-2.1.0-beta.jar
    hadoop-yarn-server-common-2.1.0-beta.jar
    hadoop-yarn-server-nodemanager-2.1.0-beta.jar

看到它是基于hadoop2.1.0的，所以我们需要用我们的hadoop2.2.0下的jar包来替换2.1的，保证版本的一致性，hadoop下的jar包都是在$HADOOP_HOME/share/hadoop下的.

我们先cd 到 /home/hadoop/hbase-0.96.0-hadoop2/lib下运行命令： rm -rf hadoop*.jar删掉所有的hadoop相关的jar包，然后运行：

    find /home/hadoop/hadoop-2.2.0/share/hadoop -name "hadoop*jar" | xargs -i cp {} /home/hadoop/hbase-0.96.0-hadoop2/lib/ 
    
拷贝所有hadoop2.2.0下的jar包hbase下进行hadoop版本的统一


4. 运行和确认安装
当Hbase托管ZooKeeper的时候

当Hbase托管ZooKeeper的时候Zookeeper集群的启动是Hbase启动脚本的一部分

首先确认你的HDFS是运行着的。你可以运行HADOOP_HOME中的 bin/start-hdfs.sh 来启动HDFS.你可以通过put命令来测试放一个文件，然后有get命令来读这个文件。通常情况下Hbase是不会运行mapreduce的。所以比不需要检查这些。

用如下命令启动Hbase:

    bin/start-hbase.sh

这个脚本在HBASE_HOME目录里面。

你现在已经启动Hbase了。Hbase把log记在 logs 子目录里面. 当Hbase启动出问题的时候，可以看看Log.

Hbase也有一个界面，上面会列出重要的属性。默认是在Master的60010端口上H (HBase RegionServers 会默认绑定 60020端口，在端口60030上有一个展示信息的界面 ).如果Master运行在 node1，端口是默认的话，你可以用浏览器在 http://node:60010看到主界面. .

一旦Hbase启动，可以看到如何建表，插入数据，scan你的表，还有disable这个表，最后把它删掉。

可以在Hbase Shell停止Hbase

    $./bin/stop-hbase.sh
    
    stoppinghbase...............

停止操作需要一些时间，你的集群越大，停的时间可能会越长。如果你正在运行一个分布式的操作，要确认在Hbase彻底停止之前，Hadoop不能停.

独立的zookeeper启动，

除了启动habse，

执行：bin/start-hbase.sh启动habse

你需要自己去运行zookeeper：

    ${HBASE_HOME}/bin/hbase-daemons.sh {start,stop} zookeeper

你可以用这条命令启动ZooKeeper而不启动Hbase. HBASE_MANAGES_ZK 的值是 false， 如果你想在Hbase重启的时候不重启ZooKeeper,你可以这样。


# 测试


可以使用jps查看进程：在master上：


在node2，node3（slave节点）上


通过浏览器查看60010端口：


1.  安装中出现的问题
1 ）

用./start-hbase.sh启动HBase后，执行hbase shell

    # bin/hbase shell
    HBase Shell; enter 'help<RETURN>' for list of supported commands.
    Version: 0.20.6, rUnknown, Thu Oct 28 19:02:04 CST 2010
    
接着创建表时候出现如下情况：hbase(main):001:0> create 'test',''c
NativeException: org.apache.hadoop.hbase.MasterNotRunningException: null

jps下，发现主节点上HMaster没有启动，查理HBase log（logs/hbase-hadoop-master-ubuntu.log）里有下面异常：
FATAL org.apache.hadoop.hbase.master.HMaster: Unhandled exception. Starting shutdown.
java.io.IOException: Call to node1/10.64.56.76:49002 failed on local exception: java.io.EOFException

解决：

从hadoop_home/下面cp一个hadoop/hadoop-core-0.20.203.0.jar到hbase_home/lib下。

因为Hbase建立在Hadoop之上，所以他用到了hadoop.jar,这个Jar在 lib 里面。这个jar是hbase自己打了branch-0.20-append 补丁的hadoop.jar. Hadoop使用的hadoop.jar和Hbase使用的 必须 一致。所以你需要将 Hbaselib 目录下的hadoop.jar替换成Hadoop里面的那个，防止版本冲突。比方说CDH的版本没有HDFS-724而branch-0.20-append里面有，这个HDFS-724补丁修改了RPC协议。如果不替换，就会有版本冲突，继而造成严重的出错，Hadoop会看起来挂了。

再用./start-hbase.sh启动HBase后，jps下，发现主节点上HMaster还是没有启动，在HBase log里有下面异常：

    FATAL org.apache.hadoop.hbase.master.HMaster: Unhandled exception. Starting shutdown.
    java.lang.NoClassDefFoundError: org/apache/commons/configuration/Configuration
    
解决：
在NoClassDefFoundError,缺少 org/apache/commons/configuration/Configuration
果断给他加一个commons-configuration包，
从hadoop_home/lib下面cp一个hadoop/lib/commons-configuration-1.6.jar到hbase_home/lib下。

（集群上所有机子的hbase配置都需要一样）


创建表报错：

    ERROR: java.io.IOException: Table Namespace Manager not ready yet, try again later
    at org.apache.hadoop.hbase.master.HMaster.getNamespaceDescriptor(HMaster.java:3101)
    at org.apache.hadoop.hbase.master.HMaster.createTable(HMaster.java:1738)
    at org.apache.hadoop.hbase.master.HMaster.createTable(HMaster.java:1777)
    at org.apache.hadoop.hbase.protobuf.generated.MasterProtos$MasterService$2.callBlockingMethod(MasterProtos.java:38221)
    at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2146)
    at org.apache.hadoop.hbase.ipc.RpcServer$Handler.run(RpcServer.java:1851)


解决：

1） 查看集群的所有机器上，

HRegionServer和HQuorumPeer进程是否都启动？

2）查看集群的所有机器的logs是不是有错误消息；

    tail -f hbase-hadoop-regionserver-XXX..log 


2  注意事项：

     1）、先启动hadoop后，再开启hbase
     2）、去掉hadoop的安全模式：hadoop dfsadmin -safemode leave
     3）、把/etc/hosts里的ubuntu的IP改为服务器当前的IP
     4)  、确认hbase的hbase-site.xml中
                      <name>hbase.rootdir</name>
                     <value>hdfs://node：49002/hbase</value>
             与hadoop的core-site.xml中
                       <name>fs.default.name</name>
                      <value>hdfs://node：49002/hbase</value>
           红字部分保持一致
    
          <value>hdfs://localhost:8020/hbase</value>
    
         否则报错：java.lang.RuntimeException: HMaster Aborted
    
     6)、重新执行./start-hbase.sh之前，先kill掉当前的hbase和zookeeper进程

7）hosts注意顺序：

    192.168.1.214 master
    192.168.1.205 node1
    192.168.1.207 node2
    192.168.1.209 node3
    192.168.1.205 T205.joy.cc


PS：遇到问题时，先查看logs，很有帮助。

HBase 官方文档，全面介绍hbase安装配置：

http://www.yankay.com/wp-content/hbase/book.html#hbase_default_configurations

# 终极boss


一、zk单独搭建

1.修改配置文件：conf/zoo.cfg

    tickTime=2000    
    dataDir=/home/hadoop/data/zookeeper    
    clientPort=2181    
    initLimit=5    
    syncLimit=2    
    server.1=slave-01:2888:3888    
    server.2=slave-02:2888:3888    
    server.3=slave-03:2888:3888   

2.生成myid文件


    在slave-01中  
    echo "1" > /home/hadoop/data/zookeeper/myid    
    在slave-02中  
    echo "2" > /home/hadoop/data/zookeeper/myid    
    在slave-03中  
    echo "3" > /home/hadoop/data/zookeeper/myid    

 

3.需要在每台机子上，启动zk

    zkServer.sh start   

4.检验zk

    zkServer.sh status   

 
二、hbase

1.修改hbase-site.xml配置文件

       

    <configuration>    
        <property>    
            <name>hbase.rootdir</name>    
            <value>hdfs://slave-1:9000/hbase</value>    
        </property>       
        <property>    
            <name>hbase.cluster.distributed</name>    
            <value>true</value>    
        </property>    
        <property>    
            <name>hbase.zookeeper.property.clientPort</name>    
            <value>2181</value>    
        </property>    
        <property>    
            <name>hbase.zookeeper.quorum</name>    
            <value>slave-01，slave-02，slave-03</value>    
        </property>    
        <property>    
            <name>hbase.zookeeper.property.dataDir</name>    
            <value>/home/hadoop/temp/zookeeper</value>    
        </property>    
        <property>    
            <name>dfs.support.append</name>    
            <value>true</value>    
        </property>    
    </configuration>    

2.hbase-env.sh

    export JAVA_HOME=/usr/lib/java/jdk1.6.0_25  //JDK的安装目录    
    export HBASE_CLASSPATH=/home/hadoop/hadoop-1.0.3/conf   //hadoop的安装目录    
    export HBASE_MANAGES_ZK=false   

3.regionservers


    slave-01  
    slave-02  
    slave-03  