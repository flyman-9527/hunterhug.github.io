---
layout: post
title: "Hbase安装"
date: 2016-08-25
author: hunterhug
categories: [工具]
desc: "Hbase安装，收集了很多资料汇总，并且修改"
tags: ["大数据","zookeeper","hbase"]
permalink: "/tool/hbase-install.html"
---

# 亲测

使用hadoop2.7.2作为文件系统，下载[hbase1.2.2](http://www.apache.org/dyn/closer.cgi/hbase/)


1.需架好外部zookeeper及hadoop，使用以下命令新建一个hadoop文件夹

     bin/hdfs dfs -mkdir /hbase

2.配置conf/hbase/env.sh，定义Java路径和zookeeper管理方式

    export JAVA_HOME=/data/app/jdk1.8.0_91
    export HBASE_MANAGES_ZK=false

3.配置conf/hbase-site.xml

    <configuration>
      <property>
        <name>hbase.rootdir</name>
        <value>hdfs://storm2:9000/hbase</value>
      </property>
     <property>  
        <name>hbase.cluster.distributed</name>  
        <value>true</value>      
      </property>
     <property>  
          <name>hbase.zookeeper.quorum</name>  
            <value>storm2</value>
    </property>
        <property>    
            <name>hbase.zookeeper.property.clientPort</name>    
            <value>2181</value>    
        </property>  
        <property>    
            <name>hbase.zookeeper.property.dataDir</name>    
            <value>/data/hadoop</value>    
        </property>  
      <property>  
            <name>hbase.master</name>  
            <value>storm2:60000</value> 
      </property>
    </configuration>
     
4.配置conf/regionservers
    
    storm2

5.配置etc/hosts

    172.16.5.12 storm2 

6.启动
    
    bin/start-hbase.sh 
 
7. 查看Web端控制台http://192.168.11.73:16010
     
#　配置解释

该文档是用hbase默认配置文件生成的，文件源是 hbase-default.xml

hbase.rootdir

    这个目录是region server的共享目录，用来持久化HBase。URL需要是'完全正确'的，还要包含文件系统的scheme。例如，要表示hdfs中的'/hbase'目录，namenode 运行在namenode.example.org的9090端口。则需要设置为hdfs://namenode.example.org:9000/hbase。默认情况下HBase是写到/tmp的。不改这个配置，数据会在重启的时候丢失。

    默认: file:///tmp/hbase-${user.name}/hbase

hbase.master.port

    HBase的Master的端口.

    默认: 60000

hbase.cluster.distributed

    HBase的运行模式。false是单机模式，true是分布式模式。若为false,HBase和Zookeeper会运行在同一个JVM里面。

    默认: false

hbase.tmp.dir

    本地文件系统的临时文件夹。可以修改到一个更为持久的目录上。(/tmp会在重启时清楚)

    默认:${java.io.tmpdir}/hbase-${user.name}

hbase.local.dir

    作为本地存储，位于本地文件系统的路径。

    默认: ${hbase.tmp.dir}/local/

hbase.master.info.port

    HBase Master web 界面端口. 设置为-1 意味着你不想让他运行。

    0.98 版本以后默认: 16010   以前是 60010

hbase.master.info.bindAddress

    HBase Master web 界面绑定的端口

    默认: 0.0.0.0

hbase.client.write.buffer

    HTable客户端的写缓冲的默认大小。这个值越大，需要消耗的内存越大。因为缓冲在客户端和服务端都有实例，所以需要消耗客户端和服务端两个地方的内存。得到的好处是，可以减少RPC的次数。可以这样估算服务器端被占用的内存： hbase.client.write.buffer * hbase.regionserver.handler.count

    默认: 2097152

hbase.regionserver.port

    HBase RegionServer绑定的端口

    0.98 以前默认: 60020 以后默认是：16020

hbase.regionserver.info.port

    HBase RegionServer web 界面绑定的端口 设置为 -1 意味这你不想与运行 RegionServer 界面.

    0.98 以前默认: 60030 以后默认是：16030

hbase.regionserver.info.port.auto

    Master或RegionServer是否要动态搜一个可以用的端口来绑定界面。当hbase.regionserver.info.port已经被占用的时候，可以搜一个空闲的端口绑定。这个功能在测试的时候很有用。默认关闭。

    默认: false

hbase.regionserver.info.bindAddress

    HBase RegionServer web 界面的IP地址

    默认: 0.0.0.0  

hbase.regionserver.class

    RegionServer 使用的接口。客户端打开代理来连接region server的时候会使用到。

    默认: org.apache.hadoop.hbase.ipc.HRegionInterface

hbase.client.pause

    通常的客户端暂停时间。最多的用法是客户端在重试前的等待时间。比如失败的get操作和region查询操作等都很可能用到。

    默认: 1000

hbase.client.retries.number

    最大重试次数。所有需重试操作的最大值。例如从root region服务器获取root region，Get单元值，行Update操作等等。这是最大重试错误的值。  Default: 10.

    0.98 以前默认: 10 以后默认是：35

hbase.bulkload.retries.number

    最大重试次数。 原子批加载尝试的迭代最大次数。 0 永不放弃。默认: 0.

    默认: 0

hbase.client.scanner.caching

    当调用Scanner的next方法，而值又不在缓存里的时候，从服务端一次获取的行数。越大的值意味着Scanner会快一些，但是会占用更多的内存。当缓冲被占满的时候，next方法调用会越来越慢。慢到一定程度，可能会导致超时。例如超过了hbase.regionserver.lease.period。

    默认: 100

hbase.client.keyvalue.maxsize

    一个KeyValue实例的最大size.这个是用来设置存储文件中的单个entry的大小上界。因为一个KeyValue是不能分割的，所以可以避免因为数据过大导致region不可分割。明智的做法是把它设为可以被最大region size整除的数。如果设置为0或者更小，就会禁用这个检查。默认10MB。

    默认: 10485760

hbase.regionserver.lease.period

    客户端租用HRegion server 期限，即超时阀值。单位是毫秒。默认情况下，客户端必须在这个时间内发一条信息，否则视为死掉。

    默认: 60000

hbase.regionserver.handler.count

    RegionServers受理的RPC Server实例数量。对于Master来说，这个属性是Master受理的handler数量

    默认: 10

hbase.regionserver.msginterval

    RegionServer 发消息给 Master 时间间隔，单位是毫秒

    默认: 3000

hbase.regionserver.optionallogflushinterval

    将Hlog同步到HDFS的间隔。如果Hlog没有积累到一定的数量，到了时间，也会触发同步。默认是1秒，单位毫秒。

    默认: 1000

hbase.regionserver.regionSplitLimit

    region的数量到了这个值后就不会在分裂了。这不是一个region数量的硬性限制。但是起到了一定指导性的作用，到了这个值就该停止分裂了。默认是MAX_INT.就是说不阻止分裂。

    默认: 2147483647

hbase.regionserver.logroll.period

    提交commit log的间隔，不管有没有写足够的值。

    默认: 3600000

hbase.regionserver.hlog.reader.impl

    HLog file reader 的实现.

    默认: org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogReader

hbase.regionserver.hlog.writer.impl

    HLog file writer 的实现.

    默认: org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogWriter
 
hbase.regionserver.nbreservationblocks

    储备的内存block的数量(译者注:就像石油储备一样)。当发生out of memory 异常的时候，我们可以用这些内存在RegionServer停止之前做清理操作。

    默认: 4

hbase.zookeeper.dns.interface

    当使用DNS的时候，Zookeeper用来上报的IP地址的网络接口名字。

    默认: default

hbase.zookeeper.dns.nameserver

    当使用DNS的时候，Zookeepr使用的DNS的域名或者IP 地址，Zookeeper用它来确定和master用来进行通讯的域名.

    默认: default

hbase.regionserver.dns.interface

    当使用DNS的时候，RegionServer用来上报的IP地址的网络接口名字。

    默认: default

hbase.regionserver.dns.nameserver

    当使用DNS的时候，RegionServer使用的DNS的域名或者IP 地址，RegionServer用它来确定和master用来进行通讯的域名.

    默认: default

hbase.master.dns.interface

    当使用DNS的时候，Master用来上报的IP地址的网络接口名字。

    默认: default

hbase.master.dns.nameserver

    当使用DNS的时候，RegionServer使用的DNS的域名或者IP 地址，Master用它来确定用来进行通讯的域名.

    默认: default

hbase.balancer.period

    Master执行region balancer的间隔。

    默认: 300000

hbase.regions.slop

    当任一区域服务器有average + (average * slop)个分区，将会执行重新均衡。默认 20% slop .

    默认:0.2

hbase.master.logcleaner.ttl

    Hlog存在于.oldlogdir 文件夹的最长时间, 超过了就会被 Master 的线程清理掉.

    默认: 600000

hbase.master.logcleaner.plugins

    LogsCleaner服务会执行的一组LogCleanerDelegat。值用逗号间隔的文本表示。这些WAL/HLog cleaners会按顺序调用。可以把先调用的放在前面。你可以实现自己的LogCleanerDelegat，加到Classpath下，然后在这里写下类的全称。一般都是加在默认值的前面。

    默认: org.apache.hadoop.hbase.master.TimeToLiveLogCleaner

hbase.regionserver.global.memstore.upperLimit

    单个region server的全部memtores的最大值。超过这个值，一个新的update操作会被挂起，强制执行flush操作。

    默认: 0.4

hbase.regionserver.global.memstore.lowerLimit

    当强制执行flush操作的时候，当低于这个值的时候，flush会停止。默认是堆大小的 35% . 如果这个值和 hbase.regionserver.global.memstore.upperLimit 相同就意味着当update操作因为内存限制被挂起时，会尽量少的执行flush(译者注:一旦执行flush，值就会比下限要低，不再执行)

    默认: 0.35

hbase.server.thread.wakefrequency

    service工作的sleep间隔，单位毫秒。 可以作为service线程的sleep间隔，比如log roller.

    默认: 10000

hbase.server.versionfile.writeattempts

    退出前尝试写版本文件的次数。每次尝试由 hbase.server.thread.wakefrequency 毫秒数间隔。

    默认: 3
     
hbase.hregion.memstore.flush.size

    当memstore的大小超过这个值的时候，会flush到磁盘。这个值被一个线程每隔hbase.server.thread.wakefrequency检查一下。

    默认:134217728

hbase.hregion.preclose.flush.size

    当一个region中的memstore的大小大于这个值的时候，我们又触发了close.会先运行“pre-flush”操作，清理这个需要关闭的memstore，然后将这个region下线。当一个region下线了，我们无法再进行任何写操作。如果一个memstore很大的时候，flush操作会消耗很多时间。"pre-flush"操作意味着在region下线之前，会先把memstore清空。这样在最终执行close操作的时候，flush操作会很快。

    默认: 5242880

hbase.hregion.memstore.block.multiplier

    如果memstore有hbase.hregion.memstore.block.multiplier倍数的hbase.hregion.flush.size的大小，就会阻塞update操作。这是为了预防在update高峰期会导致的失控。如果不设上界，flush的时候会花很长的时间来合并或者分割，最坏的情况就是引发out of memory异常。(译者注:内存操作的速度和磁盘不匹配，需要等一等。原文似乎有误)

    默认: 2

hbase.hregion.memstore.mslab.enabled

    体验特性：启用memStore分配本地缓冲区。这个特性是为了防止在大量写负载的时候堆的碎片过多。这可以减少GC操作的频率。(GC有可能会Stop the world)(译者注：实现的原理相当于预分配内存，而不是每一个值都要从堆里分配)

    默认: true

hbase.hregion.max.filesize

    最大HStoreFile大小。若某个列族的HStoreFile增长达到这个值，这个Hegion会被切割成两个。 默认: 10G.

    默认:10737418240

hbase.hstore.compactionThreshold

    当一个HStore含有多于这个值的HStoreFiles(每一个memstore flush产生一个HStoreFile)的时候，会执行一个合并操作，把这HStoreFiles写成一个。这个值越大，需要合并的时间就越长。

    默认: 3

hbase.hstore.blockingStoreFiles

    当一个HStore含有多于这个值的HStoreFiles(每一个memstore flush产生一个HStoreFile)的时候，会执行一个合并操作，update会阻塞直到合并完成，直到超过了hbase.hstore.blockingWaitTime的值

    默认: 7

hbase.hstore.blockingWaitTime

    hbase.hstore.blockingStoreFiles所限制的StoreFile数量会导致update阻塞，这个时间是来限制阻塞时间的。当超过了这个时间，HRegion会停止阻塞update操作，不过合并还有没有完成。默认为90s.

    默认: 90000

hbase.hstore.compaction.max

    每个“小”合并的HStoreFiles最大数量。

    默认: 10

hbase.hregion.majorcompaction

    一个Region中的所有HStoreFile的major compactions的时间间隔。默认是1天。 设置为0就是禁用这个功能。

    默认: 86400000

hbase.storescanner.parallel.seek.enable

    允许 StoreFileScanner 并行搜索 StoreScanner, 一个在特定条件下降低延迟的特性。

    默认: false

hbase.storescanner.parallel.seek.threads

    并行搜索特性打开后，默认线程池大小。

    默认: 10

hbase.mapreduce.hfileoutputformat.blocksize

    MapReduce中HFileOutputFormat可以写 storefiles/hfiles. 这个值是hfile的blocksize的最小值。通常在HBase写Hfile的时候，bloocksize是由table schema(HColumnDescriptor)决定的，但是在mapreduce写的时候，我们无法获取schema中blocksize。这个值越小，你的索引就越大，你随机访问需要获取的数据就越小。如果你的cell都很小，而且你需要更快的随机访问，可以把这个值调低。

    默认: 65536

hfile.block.cache.size

    分配给HFile/StoreFile的block cache占最大堆(-Xmx setting)的比例。默认0.25意思是分配25%，设置为0就是禁用，但不推荐。

    默认:0.25

hbase.hash.type

    哈希函数使用的哈希算法。可以选择两个值:: murmur (MurmurHash) 和 jenkins (JenkinsHash). 这个哈希是给 bloom filters用的

    默认: murmur

hfile.block.index.cacheonwrite

    在index写入的时候允许put无根（non-root）的多级索引块到block cache里，默认是false；

    hfile.index.block.max.size：在多级索引的树形结构里，如果任何一层的block index达到这个配置大小，则block写出，同时替换上新的block，默认是131072；

hfile.format.version

    新文件的HFile 格式版本，设置为1来测试向后兼容，默认是2；

io.storefile.bloom.block.size

    一个联合布隆过滤器的单一块（chunk）的大小，这个值是一个逼近值，默认是131072；

hfile.block.bloom.cacheonwrite

    对于组合布隆过滤器的内联block开启cache-on-write，默认是false

hbase.rs.cacheblocksonwrite

    当一个HFile block完成时是否写入block cache，默认是false

hbase.rpc.server.engine

    hbase 做rpc server的调度管理类，实现自org.apache.hadoop.ipc.RpcServerEngine，默认是org.apache.hadoop.hbase.ipc.ProtobufRpcServerEngine

hbase.ipc.client.tcpnodelay

    默认是true，具体就是在tcp socket连接时设置 no delay
     
hbase.master.keytab.file

    HMaster server验证登录使用的kerberos keytab 文件路径。(译者注：HBase使用Kerberos实现安全)

    默认:

hbase.master.kerberos.principal

    例如. "hbase/_HOST@EXAMPLE.COM". HMaster运行需要使用 kerberos principal name. principal name 可以在: user/hostname@DOMAIN 中获取. 如果 "_HOST" 被用做hostname portion，需要使用实际运行的hostname来替代它。

    默认:

hbase.regionserver.keytab.file

    HRegionServer验证登录使用的kerberos keytab 文件路径。

    默认:

hbase.regionserver.kerberos.principal

    例如. "hbase/_HOST@EXAMPLE.COM". HRegionServer运行需要使用 kerberos principal name. principal name 可以在: user/hostname@DOMAIN 中获取. 如果 "_HOST" 被用做hostname portion，需要使用实际运行的hostname来替代它。在这个文件中必须要有一个entry来描述 hbase.regionserver.keytab.file

    默认:

hadoop.policy.file

    RPC服务器做权限认证时需要的安全策略配置文件，在Hbase security开启后使用，默认是habse-policy.xml；

hbase.superuser

    Hbase security 开启后的超级用户配置，一系列由逗号隔开的user或者group；

hbase.auth.key.update.interval

    Hbase security开启后服务端更新认证key的间隔时间：默认是86400000毫秒；

hbase.auth.token.max.lifetime

    Hbase security开启后，认证token下发后的生存周期，默认是604800000毫秒
     
zookeeper.session.timeout

    ZooKeeper 会话超时.HBase把这个值传递改zk集群，向他推荐一个会话的最大超时时间。详见http://hadoop.apache.org/zookeeper/docs/current/zookeeperProgrammers.html#ch_zkSessions "The client sends a requested timeout, the server responds with the timeout that it can give the client. "。 单位是毫秒

    默认: 180000

zookeeper.znode.parent

    ZooKeeper中的HBase的根ZNode。所有的HBase的ZooKeeper会用这个目录配置相对路径。默认情况下，所有的HBase的ZooKeeper文件路径是用相对路径，所以他们会都去这个目录下面。

    默认: /hbase

zookeeper.znode.rootserver

    ZNode 保存的 根region的路径. 这个值是由Master来写，client和regionserver 来读的。如果设为一个相对地址，父目录就是 ${zookeeper.znode.parent}.默认情形下，意味着根region的路径存储在/hbase/root-region-server.

    默认: root-region-server

zookeeper.znode.acl.parent

    root znode的acl，默认acl；

hbase.coprocessor.region.classes

    逗号分隔的Coprocessores列表，会被加载到默认所有表上。在自己实现了一个Coprocessor后，将其添加到Hbase的classpath并加入全限定名。也可以延迟加载，由HTableDescriptor指定；

hbase.coprocessor.master.classes

    由HMaster进程加载的coprocessors，逗号分隔，全部实现org.apache.hadoop.hbase.coprocessor.MasterObserver，同coprocessor类似，加入classpath及全限定名；
     
hbase.zookeeper.quorum

    Zookeeper集群的地址列表，用逗号分割。例如："host1.mydomain.com,host2.mydomain.com,host3.mydomain.com".默认是localhost,是给伪分布式用的。要修改才能在完全分布式的情况下使用。如果在hbase-env.sh设置了HBASE_MANAGES_ZK，这些ZooKeeper节点就会和HBase一起启动。

    默认: localhost

hbase.zookeeper.peerport

    ZooKeeper节点使用的端口。详细参见：http://hadoop.apache.org/zookeeper/docs/r3.1.1/zookeeperStarted.html#sc_RunningReplicatedZooKeeper

    默认: 2888

hbase.zookeeper.leaderport

    ZooKeeper用来选择Leader的端口，详细参见：http://hadoop.apache.org/zookeeper/docs/r3.1.1/zookeeperStarted.html#sc_RunningReplicatedZooKeeper

    默认: 3888

hbase.zookeeper.useMulti

    Instructs HBase to make use of ZooKeeper's multi-update functionality. This allows certain ZooKeeper operations to complete more quickly and prevents some issues with rare Replication failure scenarios (see the release note of HBASE-2611 for an example). IMPORTANT: only set this to true if all ZooKeeper servers in the cluster are on version 3.4+ and will not be downgraded. ZooKeeper versions before 3.4 do not support multi-update and will not fail gracefully if multi-update is invoked (see ZOOKEEPER-1495).

    Default: false
     
hbase.zookeeper.property.initLimit

    ZooKeeper的zoo.conf中的配置。 初始化synchronization阶段的ticks数量限制

    默认: 10

hbase.zookeeper.property.syncLimit

    ZooKeeper的zoo.conf中的配置。 发送一个请求到获得承认之间的ticks的数量限制

    默认: 5

hbase.zookeeper.property.dataDir

    ZooKeeper的zoo.conf中的配置。 快照的存储位置

    默认: ${hbase.tmp.dir}/zookeeper

hbase.zookeeper.property.clientPort

    ZooKeeper的zoo.conf中的配置。 客户端连接的端口

    默认: 2181

hbase.zookeeper.property.maxClientCnxns

    ZooKeeper的zoo.conf中的配置。 ZooKeeper集群中的单个节点接受的单个Client(以IP区分)的请求的并发数。这个值可以调高一点，防止在单机和伪分布式模式中出问题。

    默认: 300

hbase.rest.port

    HBase REST server的端口

    默认: 8080

hbase.rest.readonly

    定义REST server的运行模式。可以设置成如下的值： false: 所有的HTTP请求都是被允许的 - GET/PUT/POST/DELETE. true:只有GET请求是被允许的

    默认: false

hbase.defaults.for.version.skip

    Set to true to skip the 'hbase.defaults.for.version' check. Setting this to true can be useful in contexts other than the other side of a maven generation; i.e. running in an ide. You'll want to set this boolean to true to avoid seeing the RuntimException complaint: "hbase-default.xml file seems to be for and old version of HBase (\${hbase.version}), this version is X.X.X-SNAPSHOT"

    Default: false

    是否跳过hbase.defaults.for.version的检查，默认是false；

hbase.coprocessor.abortonerror

    Set to true to cause the hosting server (master or regionserver) to abort if a coprocessor throws a Throwable object that is not IOException or a subclass of IOException. Setting it to true might be useful in development environments where one wants to terminate the server as soon as possible to simplify coprocessor failure analysis.

    Default: false

    如果coprocessor加载失败或者初始化失败或者抛出Throwable对象，则主机退出。设置为false会让系统继续运行，但是coprocessor的状态会不一致，所以一般debug时才会设置为false，默认是true；

hbase.online.schema.update.enable

    Set true to enable online schema changes. This is an experimental feature. There are known issues modifying table schemas at the same time a region split is happening so your table needs to be quiescent or else you have to be running with splits disabled.

    Default: false

    设置true来允许在线schema变更，默认是true；

hbase.table.lock.enable

    Set to true to enable locking the table in zookeeper for schema change operations. Table locking from master prevents concurrent schema modifications to corrupt table state.

    Default: true

    设置为true来允许在schema变更时zk锁表，锁表可以组织并发的schema变更导致的表状态不一致，默认是true；

dfs.support.append

    Does HDFS allow appends to files? This is an hdfs config. set in here so the hdfs client will do append support. You must ensure that this config. is true serverside too when running hbase (You will have to restart your cluster after setting it).

    Default: true

hbase.thrift.minWorkerThreads

    The "core size" of the thread pool. New threads are created on every connection until this many threads are created.

    Default: 16

    线程池的core size，在达到这里配置的量级后，新线程才会再新的连接创立时创建，默认是16；

hbase.thrift.maxWorkerThreads

    The maximum size of the thread pool. When the pending request queue overflows, new threads are created until their number reaches this number. After that, the server starts dropping connections.

    Default: 1000

    顾名思义，最大线程数，达到这个数字后，服务器开始drop连接，默认是1000；

hbase.thrift.maxQueuedRequests

    The maximum number of pending Thrift connections waiting in the queue. If there are no idle threads in the pool, the server queues requests. Only when the queue overflows, new threads are added, up to hbase.thrift.maxQueuedRequests threads.

    Default: 1000

    Thrift连接队列的最大数，如果线程池满，会先在这个队列中缓存请求，缓存上限就是该配置，默认是1000；

hbase.offheapcache.percentage

    The amount of off heap space to be allocated towards the experimental off heap cache. If you desire the cache to be disabled, simply set this value to 0.

    Default: 0

    JVM参数-XX:MaxDirectMemorySize的百分比值，默认是0，即不开启堆外分配；

hbase.data.umask.enable

    Enable, if true, that file permissions should be assigned to the files written by the regionserver

    Default: false

    开启后，文件在regionserver写入时会 有权限相关设定，默认是false不开启；

hbase.data.umask

    File permissions that should be used to write data files when hbase.data.umask.enable is true

    Default: 000

    开启上面一项配置后，文件的权限umask，默认是000

hbase.metrics.showTableName

    Whether to include the prefix "tbl.tablename" in per-column family metrics. If true, for each metric M, per-cf metrics will be reported for tbl.T.cf.CF.M, if false, per-cf metrics will be aggregated by column-family across tables, and reported for cf.CF.M. In both cases, the aggregated metric M across tables and cfs will be reported.

    Default: true

    是否为每个指标显示表名前缀，默认是true；

hbase.metrics.exposeOperationTimes

    Whether to report metrics about time taken performing an operation on the region server. Get, Put, Delete, Increment, and Append can all have their times exposed through Hadoop metrics per CF and per region.

    Default: true

    是否进行关于操作在使用时间维度的指标报告，比如GET PUT DELETE INCREMENT等，默认是true；

hbase.master.hfilecleaner.plugins

    A comma-separated list of HFileCleanerDelegate invoked by the HFileCleaner service. These HFiles cleaners are called in order, so put the cleaner that prunes the most files in front. To implement your own HFileCleanerDelegate, just put it in HBase's classpath and add the fully qualified class name here. Always add the above default log cleaners in the list as they will be overwritten in hbase-site.xml.

    Default: org.apache.hadoop.hbase.master.cleaner.TimeToLiveHFileCleaner

    HFile的清理插件列表，逗号分隔，被HFileService调用，可以自定义，默认org.apache.hadoop.hbase.master.cleaner.TimeToLiveHFileCleaner

hbase.regionserver.catalog.timeout

    Timeout value for the Catalog Janitor from the regionserver to META.

    Default: 600000

    regionserver的Catalog Janitor访问META的超时时间，默认是600000；

hbase.master.catalog.timeout

    Timeout value for the Catalog Janitor from the master to META.

    Default: 600000

    Catalog Janitor从master到META的超时时间，我们知道这个Janitor是定时的去META扫描表目录，来决定回收无用的regions，默认是600000；

hbase.config.read.zookeeper.config

    Set to true to allow HBaseConfiguration to read the zoo.cfg file for ZooKeeper properties. Switching this to true is not recommended, since the functionality of reading ZK properties from a zoo.cfg file has been deprecated.

    Default: false

    让hbaseconfig去读zk的config，默认false，也不支持开启，这个功能很搞笑~~个人观点；

hbase.snapshot.enabled

    Set to true to allow snapshots to be taken / restored / cloned.

    Default: true

    是否允许snapshot被使用、存储和克隆，默认是true；

hbase.rest.threads.max

    The maximum number of threads of the REST server thread pool. Threads in the pool are reused to process REST requests. This controls the maximum number of requests processed concurrently. It may help to control the memory used by the REST server to avoid OOM issues. If the thread pool is full, incoming requests will be queued up and wait for some free threads. The default is 100.

    Default: 100

    REST服务器线程池的最大线程数，池满的话新请求会自动排队，限制这个配置可以控制服务器的内存量，预防OOM，默认是100；

hbase.rest.threads.min

    The minimum number of threads of the REST server thread pool. The thread pool always has at least these number of threads so the REST server is ready to serve incoming requests. The default is 2.

    Default: 2

    同上类似，最小线程数，为了确保服务器的服务状态，默认是2；
    
    下面可忽略

# 资料一

## 一.zk单独搭建

1.修改配置文件：conf/zoo.cfg，端口号应该防止冲突

    tickTime=2000    
    dataDir=/home/hadoop/data/zookeeper    
    clientPort=2181    // 客户端连接地址，同台机器集群端口应该不一样
    initLimit=5    
    syncLimit=2    
    server.1=slave-01:2888:3888    
    server.2=slave-02:2888:3888    
    server.3=slave-03:2888:3888   

2.生成myid文件

    在slave-01中  
    echo "1" > /home/hadoop/data/zookeeper/myid    
    在slave-02中  
    echo "2" > /home/hadoop/data/zookeeper/myid    
    在slave-03中  
    echo "3" > /home/hadoop/data/zookeeper/myid    

3.需要在每台机子上，启动zk

    zkServer.sh start   

4.检验zk

    zkServer.sh status   
 
## 二.hbase安装配置

1.修改hbase-site.xml配置文件

    <configuration>    
        <property>    
            <name>hbase.rootdir</name>    
            <value>hdfs://slave-1:9000/hbase</value>    
        </property>       
        <property>    
            <name>hbase.cluster.distributed</name>    
            <value>true</value>    
        </property>    
        <property>    
            <name>hbase.zookeeper.property.clientPort</name>    
            <value>2181</value>    
        </property>    
        <property>    
            <name>hbase.zookeeper.quorum</name>    
            <value>slave-01，slave-02，slave-03</value>    
        </property>    
        <property>    
            <name>hbase.zookeeper.property.dataDir</name>    
            <value>/home/hadoop/temp/zookeeper</value>    
        </property>    
        <property>    
            <name>dfs.support.append</name>    
            <value>true</value>    
        </property>    
    </configuration>    

2.hbase-env.sh

    export JAVA_HOME=/usr/lib/java/jdk1.6.0_25  //JDK的安装目录    
    export HBASE_CLASSPATH=/home/hadoop/hadoop-1.0.3/conf   //hadoop的安装目录    
    export HBASE_MANAGES_ZK=false   

3.regionservers

    slave-01  
    slave-02  
    slave-03
    
4.启动后输入16010端口

现在启动Hbase:

    $ ./bin/start-hbase.sh
    
    starting Master, logging to logs/hbase-user-master-example.org.out

<img src="/img/hbase.jpg"/>


# 资料二

## 一.快速安装

> 在单机安装Hbase的方法。会引导你通过shell创建一个表，插入一行，然后删除它，最后停止Hbase。只要10分钟就可以完成以下的操作。

1.下载解压最新版本

选择一个 Apache 下载镜像：http://www.apache.org/dyn/closer.cgi/hbase/，下载 HBase Releases. 点击 stable目录，然后下载后缀为 .tar.gz 的文件; 例如 hbase-0.90.4.tar.gz.

后面需要安装集群，整合到hadoop，所以注意选择与hadoop对应的版本：

选择 Hadoop 版本对HBase部署很关键。下表显示不同HBase支持的Hadoop版本信息。基于HBase版本，应该选择合适的Hadoop版本。我们没有绑定 Hadoop 发行版选择。可以从Apache使用 Hadoop 发行版，或了解一下Hadoop发行商产品： http://wiki.apache.org/hadoop/Distributions%20and%20Commercial%20Support

    Table 2.1. Hadoop version support matrix
        HBase-0.92.x 	HBase-0.94.x 	HBase-0.96
    Hadoop-0.20.205 	S 	X 	X
    Hadoop-0.22.x 	S 	X 	X
    Hadoop-1.0.x 	S 	S 	S
    Hadoop-1.1.x 	NT 	S 	S
    Hadoop-0.23.x 	X 	S 	NT
    Hadoop-2.x 	X 	S 	S

>S = supported and tested,支持

>X = not supported,不支持

>NT = not tested enough.可以运行但测试不充分

由于 HBase 依赖 Hadoop，它配套发布了一个Hadoop jar 文件在它的 lib 下。该套装jar仅用于独立模式。在分布式模式下，Hadoop版本必须和HBase下的版本一致。用你运行的分布式Hadoop版本jar文件替换HBase lib目录下的Hadoop jar文件，以避免版本不匹配问题。确认替换了集群中所有HBase下的jar文件。Hadoop版本不匹配问题有不同表现，但看起来都像挂掉了。

安装：

    $ tar xfz hbase-0.90.4.tar.gz
    $ cd hbase-0.90.4

现在你已经可以启动Hbase了。但是你可能需要先编辑 conf/hbase-site.xml 去配置hbase.rootdir，来选择Hbase将数据写到哪个目录 .

单机配置，只需要如下配置hbase-site.xml：

    <?xml version="1.0"?>  
    <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>  
    <configuration>  
      <property>  
        <name>hbase.rootdir</name>  
        <value>file:///DIRECTORY/hbase</value>  
      </property>  
    </configuration>  

将 DIRECTORY 替换成你期望写文件的目录. 默认 hbase.rootdir 是指向 /tmp/hbase-${user.name} ，也就说你会在重启后丢失数据(重启的时候操作系统会清理/tmp目录)

2.启动 HBase

现在启动Hbase:

    $ ./bin/start-hbase.sh
    
    starting Master, logging to logs/hbase-user-master-example.org.out

现在你运行的是单机模式的Hbaes。所以的服务都运行在一个JVM上，包括Hbase和Zookeeper。Hbase的日志放在logs目录,当你启动出问题的时候，可以检查这个日志。

3.Hbase Shell 练习

用shell连接你的Hbase

    $ ./bin/hbase shell
    
    HBase Shell; enter 'help<RETURN>' for list of supported commands.
    Type "exit<RETURN>" to leave the HBase Shell
    Version: 0.90.0, r1001068, Fri Sep 24 13:55:42 PDT 2010
    
    hbase(main):001:0> 

输入 help 然后 <RETURN> 可以看到一列shell命令。这里的帮助很详细，要注意的是表名，行和列需要加引号。

创建一个名为 test 的表，这个表只有一个column family 为 cf。可以列出所有的表来检查创建情况，然后插入些值。

    hbase(main):003:0> create 'test', 'cf'
    0 row(s) in 1.2200 seconds
    hbase(main):003:0> list 'table'
    test
    1 row(s) in 0.0550 seconds
    hbase(main):004:0> put 'test', 'row1', 'cf:a', 'value1'
    0 row(s) in 0.0560 seconds
    hbase(main):005:0> put 'test', 'row2', 'cf:b', 'value2'
    0 row(s) in 0.0370 seconds
    hbase(main):006:0> put 'test', 'row3', 'cf:c', 'value3'
    0 row(s) in 0.0450 seconds

以上我们分别插入了3行。第一个行key为row1, 列为 cf:a， 值是 value1。Hbase中的列是由 column family前缀和列的名字组成的，以冒号间隔。例如这一行的列名就是a.

检查插入情况.

Scan这个表，操作如下

    hbase(main):007:0> scan 'test'
    
    ROW        COLUMN+CELL
    row1       column=cf:a, timestamp=1288380727188, value=value1
    row2       column=cf:b, timestamp=1288380738440, value=value2
    row3       column=cf:c, timestamp=1288380747365, value=value3
    
    3 row(s) in 0.0590 seconds

Get一行，操作如下

    hbase(main):008:0> get 'test', 'row1'

        COLUMN      CELL
        cf:a        timestamp=1288380727188, value=value1
        1 row(s) in 0.0400 seconds

disable 再 drop 这张表，可以清除你刚刚的操作

    hbase(main):012:0> disable 'test'
    0 row(s) in 1.0930 seconds
    hbase(main):013:0> drop 'test'
    0 row(s) in 0.0770 seconds 

关闭shell

    hbase(main):014:0> exit

4.停止 HBase

运行停止脚本来停止HBase.

    $ ./bin/stop-hbase.sh
    stopping hbase...............

## 二.集群安装注意

1）Java：（hadoop已经安装了）

2）Hadoop 0.20.x / Hadoop-2.x 已经正确安装，并且可以启动 HDFS 系统, 可参考的Hadoop安装文档：Hadoop集群配置（最全面总结）http://blog.csdn.net/hguisu/article/details/7237395

3）ssh 必须安装ssh，sshd 也必须运行，这样Hadoop的脚本才可以远程操控其他的Hadoop和Hbase进程。ssh之间必须都打通，不用密码都可以登录，详细方法可以Google一下 ("ssh passwordless login").

4）NTP：集群的时钟要保证基本的一致。稍有不一致是可以容忍的，但是很大的不一致会 造成奇怪的行为。 运行 NTP 或者其他什么东西来同步你的时间.

如果你查询的时候或者是遇到奇怪的故障，可以检查一下系统时间是否正确!

设置集群各个节点时钟：date -s “2012-02-13 14:00:00”

5）ulimit 和 nproc:

Base是数据库，会在同一时间使用很多的文件句柄。大多数linux系统使用的默认值1024是不能满足的，会导致FAQ: Why do I see "java.io.IOException...(Too manyopen files)" in my logs?异常。还可能会发生这样的异常

     2010-04-06 03:04:37,542 INFO org.apache.hadoop.hdfs.DFSClient: ExceptionincreateBlockOutputStream java.io.EOFException

     2010-04-06 03:04:37,542 INFO org.apache.hadoop.hdfs.DFSClient:Abandoning block blk_-6935524980745310745_1391901

所以你需要修改你的最大文件句柄限制。可以设置到10k. 你还需要修改 hbase 用户的 nproc，如果过低会造成 OutOfMemoryError异常。

需要澄清的，这两个设置是针对操作系统的，不是Hbase本身的。有一个常见的错误是Hbase运行的用户，和设置最大值的用户不是一个用户。在Hbase启动的时候，第一行日志会现在ulimit信息，所以你最好检查一下。 

可以先查看当前用户 ulimit：

    ulimit -n

设置ulimit:

如果你使用的是Ubuntu,你可以这样设置:在文件 /etc/security/limits.conf 添加一行，如:

    hadoop  -       nofile 32768

可以把 hadoop 替换成你运行Hbase和Hadoop的用户。如果你用两个用户，你就需要配两个。还有配nproc hard 和 softlimits. 如:

    hadoop soft/hard nproc 32000

在 /etc/pam.d/common-session 加上这一行:

    session required pam_limits.so

否则在 /etc/security/limits.conf上的配置不会生效.

还有注销再登录，这些配置才能生效!

7）修改Hadoop HDFS Datanode同时处理文件的上限：dfs.datanode.max.xcievers

一个 Hadoop HDFS Datanode 有一个同时处理文件的上限. 这个参数叫 xcievers (Hadoop的作者把这个单词拼错了). 在你加载之前，先确认下你有没有配置这个文件conf/hdfs-site.xml里面的xceivers参数，至少要有4096:

      <property>

       <name>dfs.datanode.max.xcievers</name>

        <value>4096</value>

      </property>

对于HDFS修改配置要记得重启.

如果没有这一项配置，你可能会遇到奇怪的失败。你会在Datanode的日志中看到xcievers exceeded，但是运行起来会报 missing blocks错误。例如: 02/12/1220:10:31 INFO hdfs.DFSClient: Could not obtain blockblk_XXXXXXXXXXXXXXXXXXXXXX_YYYYYYYY from any node: java.io.IOException: No livenodes contain current block. Will get new block locations from namenode andretry...

8）继承hadoop安装的说明：

每个机子/etc/hosts

    10.64.56.74  node2 （master）
    10.64.56.76  node1  （slave）
    10.64.56.77  node3 （slave）

9） 继续使用hadoop用户安装

    Chown –R hadoop /usr/local/hbase

## 三.分布式模式配置

1.配置conf/hbase-env.sh

        # exportJAVA_HOME=/usr/java/jdk1.6.0/
        exportJAVA_HOME=/usr/lib/jvm/java-6-sun-1.6.0.26
        # Tell HBase whether it should manage it'sown instance of Zookeeper or not.
        export HBASE_MANAGES_ZK=true

不管是什么模式，你都需要编辑 conf/hbase-env.sh来告知Hbase java的安装路径.在这个文件里你还可以设置Hbase的运行环境，诸如 heapsize和其他 JVM有关的选项, 还有Log文件地址，等等. 设置 JAVA_HOME指向 java安装的路径.

一个分布式运行的Hbase依赖一个zookeeper集群。所有的节点和客户端都必须能够访问zookeeper。默认的情况下Hbase会管理一个zookeep集群。这个集群会随着Hbase的启动而启动。当然，你也可以自己管理一个zookeeper集群，但需要配置Hbase。你需要修改conf/hbase-env.sh里面的HBASE_MANAGES_ZK 来切换。这个值默认是true的，作用是让Hbase启动的时候同时也启动zookeeper.

让Hbase使用一个现有的不被Hbase托管的Zookeep集群，需要设置 conf/hbase-env.sh文件中的HBASE_MANAGES_ZK 属性为 false

        # Tell HBase whether it should manage it's own instanceof Zookeeper or not.
        exportHBASE_MANAGES_ZK=false

2.配置conf/hbase-site.xml

    <configuration>  
        <property>
        <name>hbase.rootdir</name>  
        <value>hdfs://node1:49002/hbase</value>  
        <description>The directory shared byRegionServers.  
        </description>  
      </property>  
    
      <property>  
        <name>hbase.cluster.distributed</name>  
        <value>true</value>  
        <description>The mode the clusterwill be in. Possible values are  
          false: standalone and pseudo-distributedsetups with managed Zookeeper  
          true: fully-distributed with unmanagedZookeeper Quorum (see hbase-env.sh)  
        </description>  
      </property>  
      
        <property>  
          <name>hbase.zookeeper.property.clientPort</name>  
          <value>2222</value>  
          <description>Property fromZooKeeper's config zoo.cfg.  
          The port at which the clients willconnect.  
          </description>  
        </property>  
      
        <property>  
          <name>hbase.zookeeper.quorum</name>  
          <value>node1,node2,node3</value>  
          <description>Comma separated listof servers in the ZooKeeper Quorum.  
          For example,"host1.mydomain.com,host2.mydomain.com,host3.mydomain.com".  
          By default this is set to localhost forlocal and pseudo-distributed modes  
          of operation. For a fully-distributedsetup, this should be set to a full  
          list of ZooKeeper quorum servers. IfHBASE_MANAGES_ZK is set in hbase-env.sh  
          this is the list of servers which we willstart/stop ZooKeeper on.  
          </description>  
        </property>  
        
        <property>  
          <name>hbase.zookeeper.property.dataDir</name>  
          <value>/home/hadoop/zookeeper</value>  
          <description>Property fromZooKeeper's config zoo.cfg.  
          The directory where the snapshot isstored.  
          </description>
        </property>
      </configuration>  

要想运行完全分布式模式，加一个属性 hbase.cluster.distributed 设置为 true 然后把 hbase.rootdir 设置为HDFS的NameNode的位置。 例如，你的namenode运行在node1，端口是49002 你期望的目录是 /hbase,使用如下的配置：hdfs://node1:49002/hbase

>hbase.rootdir：这个目录是region server的共享目录，用来持久化Hbase。URL需要是'完全正确'的，还要包含文件系统的scheme。
例如，要表示hdfs中的'/hbase'目录，namenode 运行在node1的49002端口。则需要设置为hdfs://node1:49002/hbase。默认情况下Hbase是写到/tmp的。
不改这个配置，数据会在重启的时候丢失。默认: file:///tmp/hbase-${user.name}/hbase

>hbase.cluster.distributed ：Hbase的运行模式。false是单机模式，true是分布式模式。若为false,Hbase和Zookeeper会运行在同一个JVM里面。默认: false

>在hbase-site.xml配置zookeeper：当Hbase管理zookeeper的时候，你可以通过修改zoo.cfg来配置zookeeper，
一个更加简单的方法是在 conf/hbase-site.xml里面修改zookeeper的配置。Zookeeer的配置是作为property写在 hbase-site.xml里面的。
对于zookeepr的配置，你至少要在 hbase-site.xml中列出zookeepr的ensemble servers，具体的字段是 hbase.zookeeper.quorum. 该这个字段的默认值是 localhost，这个值对于分布式应用显然是不可以的. (远程连接无法使用)。

>hbase.zookeeper.property.clientPort：ZooKeeper的zoo.conf中的配置。 客户端连接的端口。

>hbase.zookeeper.quorum：Zookeeper集群的地址列表，用逗号分割。例如："host1.mydomain.com,host2.mydomain.com,host3.mydomain.com".默认是localhost,是给伪分布式用的。要修改才能在完全分布式的情况下使用。如果在hbase-env.sh设置了HBASE_MANAGES_ZK，这些ZooKeeper节点就会和Hbase一起启动。
默认: localhost
运行一个zookeeper也是可以的，但是在生产环境中，你最好部署3，5，7个节点。部署的越多，可靠性就越高，当然只能部署奇数个，偶数个是不可以的。你需要给每个zookeeper 1G左右的内存，如果可能的话，最好有独立的磁盘。 (独立磁盘可以确保zookeeper是高性能的。).如果你的集群负载很重，不要把Zookeeper和RegionServer运行在同一台机器上面。就像DataNodes 和 TaskTrackers一样

>hbase.zookeeper.property.dataDir：ZooKeeper的zoo.conf中的配置。 快照的存储位置
把ZooKeeper保存数据的目录地址改掉。默认值是 /tmp ，这里在重启的时候会被操作系统删掉，可以把它修改到 /home/hadoop/zookeeper (这个路径hadoop用户拥有操作权限)
对于独立的Zookeeper，要指明Zookeeper的host和端口。可以在 hbase-site.xml中设置, 也可以在Hbase的CLASSPATH下面加一个zoo.cfg配置文件。 HBase 会优先加载 zoo.cfg 里面的配置，把hbase-site.xml里面的覆盖掉.
参见 http://www.yankay.com/wp-content/hbase/book.html#hbase_default_configurations可以查找hbase.zookeeper.property 前缀，找到关于zookeeper的配置。

3.配置conf/regionservers
    
    Node1
    Node2

完全分布式模式的还需要修改conf/regionservers. 在这里列出了你希望运行的全部 HRegionServer，一行写一个host (就像Hadoop里面的 slaves 一样). 列在这里的server会随着集群的启动而启动，集群的停止而停止.

4.替换hadoop的jar包

hbase基本的配置完了。

查看hbase的lib目录下。

    ls lib |grep hadoop
    
    hadoop-annotations-2.1.0-beta.jar
    hadoop-auth-2.1.0-beta.jar
    hadoop-client-2.1.0-beta.jar
    hadoop-common-2.1.0-beta.jar
    hadoop-hdfs-2.1.0-beta.jar
    hadoop-hdfs-2.1.0-beta-tests.jar
    hadoop-mapreduce-client-app-2.1.0-beta.jar
    hadoop-mapreduce-client-common-2.1.0-beta.jar
    hadoop-mapreduce-client-core-2.1.0-beta.jar
    hadoop-mapreduce-client-jobclient-2.1.0-beta.jar
    hadoop-mapreduce-client-jobclient-2.1.0-beta-tests.jar
    hadoop-mapreduce-client-shuffle-2.1.0-beta.jar
    hadoop-yarn-api-2.1.0-beta.jar
    hadoop-yarn-client-2.1.0-beta.jar
    hadoop-yarn-common-2.1.0-beta.jar
    hadoop-yarn-server-common-2.1.0-beta.jar
    hadoop-yarn-server-nodemanager-2.1.0-beta.jar

看到它是基于hadoop2.1.0的，所以我们需要用我们的hadoop2.2.0下的jar包来替换2.1的，保证版本的一致性，hadoop下的jar包都是在$HADOOP_HOME/share/hadoop下的.

我们先cd 到 /home/hadoop/hbase-0.96.0-hadoop2/lib下运行命令： rm -rf hadoop*.jar删掉所有的hadoop相关的jar包，然后运行：

    find /home/hadoop/hadoop-2.2.0/share/hadoop -name "hadoop*jar" | xargs -i cp {} /home/hadoop/hbase-0.96.0-hadoop2/lib/ 
    
拷贝所有hadoop2.2.0下的jar包hbase下进行hadoop版本的统一


5.运行和确认安装

当Hbase托管ZooKeeper的时候

当Hbase托管ZooKeeper的时候Zookeeper集群的启动是Hbase启动脚本的一部分

首先确认你的HDFS是运行着的。你可以运行HADOOP_HOME中的 bin/start-hdfs.sh 来启动HDFS.你可以通过put命令来测试放一个文件，然后有get命令来读这个文件。通常情况下Hbase是不会运行mapreduce的。所以比不需要检查这些。

用如下命令启动Hbase:

    bin/start-hbase.sh

这个脚本在HBASE_HOME目录里面。

你现在已经启动Hbase了。Hbase把log记在 logs 子目录里面. 当Hbase启动出问题的时候，可以看看Log.

Hbase也有一个界面，上面会列出重要的属性。默认是在Master的60010端口上H (HBase RegionServers 会默认绑定 60020端口，在端口60030上有一个展示信息的界面 ).如果Master运行在 node1，端口是默认的话，你可以用浏览器在 http://node:60010看到主界面. .

一旦Hbase启动，可以看到如何建表，插入数据，scan你的表，还有disable这个表，最后把它删掉。

可以在Hbase Shell停止Hbase

    $./bin/stop-hbase.sh
    
    stoppinghbase...............

停止操作需要一些时间，你的集群越大，停的时间可能会越长。如果你正在运行一个分布式的操作，要确认在Hbase彻底停止之前，Hadoop不能停.

独立的zookeeper启动，

除了启动habse，

执行：bin/start-hbase.sh启动habse

你需要自己去运行zookeeper：

    ${HBASE_HOME}/bin/hbase-daemons.sh {start,stop} zookeeper

你可以用这条命令启动ZooKeeper而不启动Hbase. HBASE_MANAGES_ZK 的值是 false， 如果你想在Hbase重启的时候不重启ZooKeeper,你可以这样。

## 四.测试

可以使用jps查看进程：在master上：

在node2，node3（slave节点）上

通过浏览器查看60010端口：

1.安装中出现的问题

用./start-hbase.sh启动HBase后，执行hbase shell

    # bin/hbase shell
    HBase Shell; enter 'help<RETURN>' for list of supported commands.
    Version: 0.20.6, rUnknown, Thu Oct 28 19:02:04 CST 2010
    
接着创建表时候出现如下情况：hbase(main):001:0> create 'test',''c
NativeException: org.apache.hadoop.hbase.MasterNotRunningException: null

jps下，发现主节点上HMaster没有启动，查理HBase log（logs/hbase-hadoop-master-ubuntu.log）里有下面异常：
FATAL org.apache.hadoop.hbase.master.HMaster: Unhandled exception. Starting shutdown.
java.io.IOException: Call to node1/10.64.56.76:49002 failed on local exception: java.io.EOFException

解决：

从hadoop_home/下面cp一个hadoop/hadoop-core-0.20.203.0.jar到hbase_home/lib下。

因为Hbase建立在Hadoop之上，所以他用到了hadoop.jar,这个Jar在 lib 里面。这个jar是hbase自己打了branch-0.20-append 补丁的hadoop.jar. Hadoop使用的hadoop.jar和Hbase使用的 必须 一致。所以你需要将 Hbaselib 目录下的hadoop.jar替换成Hadoop里面的那个，防止版本冲突。比方说CDH的版本没有HDFS-724而branch-0.20-append里面有，这个HDFS-724补丁修改了RPC协议。如果不替换，就会有版本冲突，继而造成严重的出错，Hadoop会看起来挂了。

再用./start-hbase.sh启动HBase后，jps下，发现主节点上HMaster还是没有启动，在HBase log里有下面异常：

    FATAL org.apache.hadoop.hbase.master.HMaster: Unhandled exception. Starting shutdown.
    java.lang.NoClassDefFoundError: org/apache/commons/configuration/Configuration
    
解决：
在NoClassDefFoundError,缺少 org/apache/commons/configuration/Configuration
果断给他加一个commons-configuration包，
从hadoop_home/lib下面cp一个hadoop/lib/commons-configuration-1.6.jar到hbase_home/lib下。

（集群上所有机子的hbase配置都需要一样）

创建表报错：

    ERROR: java.io.IOException: Table Namespace Manager not ready yet, try again later
    at org.apache.hadoop.hbase.master.HMaster.getNamespaceDescriptor(HMaster.java:3101)
    at org.apache.hadoop.hbase.master.HMaster.createTable(HMaster.java:1738)
    at org.apache.hadoop.hbase.master.HMaster.createTable(HMaster.java:1777)
    at org.apache.hadoop.hbase.protobuf.generated.MasterProtos$MasterService$2.callBlockingMethod(MasterProtos.java:38221)
    at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2146)
    at org.apache.hadoop.hbase.ipc.RpcServer$Handler.run(RpcServer.java:1851)

解决：

1） 查看集群的所有机器上，

HRegionServer和HQuorumPeer进程是否都启动？

2）查看集群的所有机器的logs是不是有错误消息；

    tail -f hbase-hadoop-regionserver-XXX..log 

注意事项：

     1）、先启动hadoop后，再开启hbase
     2）、去掉hadoop的安全模式：hadoop dfsadmin -safemode leave
     3）、把/etc/hosts里的ubuntu的IP改为服务器当前的IP
     4)  、确认hbase的hbase-site.xml中
                      <name>hbase.rootdir</name>
                     <value>hdfs://node：49002/hbase</value>
             与hadoop的core-site.xml中
                       <name>fs.default.name</name>
                      <value>hdfs://node：49002/hbase</value>
           红字部分保持一致
    
          <value>hdfs://localhost:8020/hbase</value>
    
         否则报错：java.lang.RuntimeException: HMaster Aborted
    
     6)、重新执行./start-hbase.sh之前，先kill掉当前的hbase和zookeeper进程

hosts注意顺序：

    192.168.1.214 master
    192.168.1.205 node1
    192.168.1.207 node2
    192.168.1.209 node3
    192.168.1.205 T205.joy.cc


PS：遇到问题时，先查看logs，很有帮助。

HBase 官方文档，全面介绍hbase安装配置：

http://www.yankay.com/wp-content/hbase/book.html#hbase_default_configurations
